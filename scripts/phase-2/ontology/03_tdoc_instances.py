#!/usr/bin/env python3
"""
Phase C: Tdoc/CR/LS ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

Spec ê¸°ë°˜: docs/phase-2/specs/tdoc-ontology-spec.md Step 7.3.9~7.3.11
ì…ë ¥: ontology/input/meetings/RAN1/*.xlsx (59ê°œ íŒŒì¼)
ì¶œë ¥: ontology/output/instances/tdocs.jsonld

í´ë˜ìŠ¤ë³„ íŒë‹¨ ë¡œì§ (Spec 4.5):
- CR: Typeì´ 'CR', 'draftCR', 'pCR'
- LS: Typeì´ 'LS out', 'LS in'
- Tdoc: ê·¸ ì™¸ ëª¨ë“  Type
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from collections import defaultdict
import pandas as pd
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
INPUT_DIR = BASE_DIR / "input" / "meetings" / "RAN1"
INTERMEDIATE_DIR = BASE_DIR / "intermediate"
OUTPUT_DIR = BASE_DIR / "output" / "instances"

# JSON-LD ì»¨í…ìŠ¤íŠ¸
# Note: Relations must have "@type": "@id" to be recognized as relationships by n10s
CONTEXT = {
    "@context": {
        "tdoc": "http://3gpp.org/ontology/tdoc#",
        "dc": "http://purl.org/dc/elements/1.1/",
        "foaf": "http://xmlns.com/foaf/0.1/",
        "xsd": "http://www.w3.org/2001/XMLSchema#",
        # Relations - must be @id type for n10s to create relationships
        "modifies": {"@id": "tdoc:modifies", "@type": "@id"},
        "replyTo": {"@id": "tdoc:replyTo", "@type": "@id"},
        "sentTo": {"@id": "tdoc:sentTo", "@type": "@id"},
        "hasContact": {"@id": "tdoc:hasContact", "@type": "@id"},
        "belongsTo": {"@id": "tdoc:belongsTo", "@type": "@id"},
        "presentedAt": {"@id": "tdoc:presentedAt", "@type": "@id"},
        "submittedBy": {"@id": "tdoc:submittedBy", "@type": "@id"},
        "originatedFrom": {"@id": "tdoc:originatedFrom", "@type": "@id"},
    }
}

# CR íƒ€ì…
CR_TYPES = {'CR', 'draftCR', 'pCR'}

# LS íƒ€ì…
LS_TYPES = {'LS out', 'LS in'}

# Working Group íŒ¨í„´ (Issue #1, #5 í•´ê²°ìš©)
# Source ì»¬ëŸ¼ì— WGì™€ Companyê°€ í˜¼í•©ë˜ì–´ ìˆìŒ (ì˜ˆ: "RAN3, Huawei")
# ì´ë¥¼ ë¶„ë¦¬í•˜ì—¬ WGëŠ” ORIGINATED_FROM, CompanyëŠ” SUBMITTED_BY ê´€ê³„ë¡œ ì—°ê²°
WG_PATTERNS = [
    r'^RAN\d?$',      # RAN, RAN1-6
    r'^SA\d?$',       # SA, SA1-6
    r'^CT\d?$',       # CT, CT1-6
    r'^TSG[ _]?RAN$', # TSG RAN
    r'^TSG[ _]?SA$',  # TSG SA
    r'^TSG[ _]?CT$',  # TSG CT
]

# ì—­í•  íŒ¨í„´ (Chair, Rapporteur ë“±)
ROLE_PATTERNS = [
    r'.*[Cc]hair.*',
    r'.*[Cc]hairman.*',
]


def load_company_aliases() -> Dict[str, str]:
    """Company ë³„ì¹­ â†’ ì •ê·œí™” ë§µ ë¡œë“œ"""
    aliases_path = INTERMEDIATE_DIR / "company_aliases_significant.json"
    reverse_map = {}

    if aliases_path.exists():
        with open(aliases_path, 'r', encoding='utf-8') as f:
            aliases = json.load(f)

        for canonical, data in aliases.items():
            for alias in data.get("aliases", []):
                reverse_map[alias.lower()] = canonical
            reverse_map[canonical.lower()] = canonical

    return reverse_map


def load_reference_data() -> Dict[str, set]:
    """Reference í´ë˜ìŠ¤ ë°ì´í„° ë¡œë“œ (ìœ íš¨ì„± ê²€ì¦ìš©)"""
    summary_path = INTERMEDIATE_DIR / "reference_summary.json"
    if summary_path.exists():
        with open(summary_path, 'r', encoding='utf-8') as f:
            return {k: set(v) for k, v in json.load(f).items()}
    return {}


def extract_meeting_from_filename(filename: str) -> str:
    """íŒŒì¼ëª…ì—ì„œ Meeting ID ì¶”ì¶œ"""
    match = re.search(r'TSGR1_(\d+)([a-z]?)(?:[-_]?(e))?', filename, re.IGNORECASE)
    if match:
        meeting_num = match.group(1)
        letter_suffix = match.group(2) if match.group(2) else ""
        e_suffix = match.group(3) if match.group(3) else ""
        suffix = letter_suffix
        if e_suffix:
            suffix = f"{letter_suffix}-e"
        return f"RAN1#{meeting_num}{suffix}"
    return None


def classify_tdoc_type(type_value: str) -> str:
    """Type ê°’ìœ¼ë¡œ í´ë˜ìŠ¤ ë¶„ë¥˜

    Spec 4.5 Typeë³„ í´ë˜ìŠ¤ ë§¤í•‘:
    - CR: CR, draftCR, pCR
    - LS: LS out, LS in
    - Tdoc: ê·¸ ì™¸ ëª¨ë“  ê°’
    """
    if pd.isna(type_value):
        return "Tdoc"

    type_value = str(type_value).strip()

    if type_value in CR_TYPES:
        return "CR"
    elif type_value in LS_TYPES:
        return "LS"
    else:
        return "Tdoc"


def is_working_group(name: str) -> bool:
    """Working Group íŒ¨í„´ì¸ì§€ í™•ì¸

    Issue #1, #5: Source ì»¬ëŸ¼ì— WGì™€ Companyê°€ í˜¼í•©ë¨
    ì˜ˆ: "RAN3, Huawei" â†’ RAN3ëŠ” WG, HuaweiëŠ” Company
    """
    name = name.strip()
    for pattern in WG_PATTERNS:
        if re.match(pattern, name, re.IGNORECASE):
            return True
    return False


def is_role(name: str) -> bool:
    """ì—­í•  íŒ¨í„´ì¸ì§€ í™•ì¸ (Chair, Rapporteur ë“±)"""
    name = name.strip()
    for pattern in ROLE_PATTERNS:
        if re.match(pattern, name, re.IGNORECASE):
            return True
    return False


def parse_submitters(source: str, company_map: Dict[str, str]) -> Tuple[List[str], List[str]]:
    """Source ì»¬ëŸ¼ì—ì„œ íšŒì‚¬ì™€ Working Groupì„ ë¶„ë¦¬ ì¶”ì¶œ

    Issue #1, #5 í•´ê²°: WGì™€ Companyë¥¼ ë¶„ë¦¬í•˜ì—¬ ë‹¤ë¥¸ ê´€ê³„ë¡œ ì—°ê²°
    - Company â†’ SUBMITTED_BY ê´€ê³„
    - WorkingGroup â†’ ORIGINATED_FROM ê´€ê³„

    Spec 7.6.3: ê´„í˜¸ ë‚´ ì‰¼í‘œ ë³´í˜¸ â†’ ì—­í•  ë¶„ë¦¬ â†’ ì‰¼í‘œë¡œ ë¶„ë¦¬

    Returns:
        Tuple[List[str], List[str]]: (companies, working_groups)
    """
    if pd.isna(source) or not str(source).strip():
        return [], []

    source = str(source)

    # ì—­í•  íŒ¨í„´ ì œê±°: "Moderator (Samsung)" â†’ "Samsung"
    role_pattern = r'^(?:Moderator|Rapporteur|WI [Rr]apporteur|Ad-Hoc Chair|.*Chair)\s*\(([^)]+)\)$'
    match = re.match(role_pattern, source)
    if match:
        source = match.group(1)

    # ê´„í˜¸ ì•ˆì˜ ì‰¼í‘œ ë³´í˜¸
    protected = re.sub(r'\(([^)]*),([^)]*)\)', lambda m: m.group(0).replace(',', 'Â§'), source)

    # ì‰¼í‘œë¡œ ë¶„ë¦¬
    parts = [p.strip().replace('Â§', ',') for p in protected.split(',')]

    # ë¶„ë¥˜: Company vs WorkingGroup
    companies = []
    working_groups = []

    for part in parts:
        if not part:
            continue

        # ì—­í• ì—ì„œ íšŒì‚¬ ì¶”ì¶œ
        role_match = re.match(role_pattern, part)
        if role_match:
            part = role_match.group(1)

        # WG íŒ¨í„´ í™•ì¸
        if is_working_group(part):
            wg_name = part.upper()  # ì •ê·œí™”: RAN3, SA2 ë“±
            if wg_name not in working_groups:
                working_groups.append(wg_name)
        # ì—­í•  íŒ¨í„´ì€ ê±´ë„ˆëœ€ (RAN1_Chair ë“±)
        elif is_role(part):
            continue
        # ì¼ë°˜ íšŒì‚¬
        else:
            normalized = company_map.get(part.lower(), part)
            if normalized and normalized not in companies:
                companies.append(normalized)

    return companies, working_groups


def parse_companies(source: str, company_map: Dict[str, str]) -> List[str]:
    """Source ì»¬ëŸ¼ì—ì„œ íšŒì‚¬ ëª©ë¡ ì¶”ì¶œ ë° ì •ê·œí™” (í•˜ìœ„ í˜¸í™˜ì„±ìš©)

    Note: parse_submitters()ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥
    """
    companies, _ = parse_submitters(source, company_map)
    return companies


def parse_work_items(value: str) -> List[str]:
    """Related WIs ì»¬ëŸ¼ íŒŒì‹±"""
    if pd.isna(value) or not str(value).strip():
        return []
    return [item.strip() for item in str(value).split(',') if item.strip()]


def parse_working_groups(value: str) -> List[str]:
    """To/Cc ì»¬ëŸ¼ íŒŒì‹±"""
    if pd.isna(value) or not str(value).strip():
        return []
    return [item.strip() for item in str(value).split(',') if item.strip()]


def safe_string(value) -> Optional[str]:
    """ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if pd.isna(value):
        return None
    s = str(value).strip()
    return s if s else None


def safe_datetime(value) -> Optional[str]:
    """ë‚ ì§œ/ì‹œê°„ ê°’ì„ ISO í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if pd.isna(value):
        return None
    try:
        if isinstance(value, datetime):
            return value.isoformat()
        return str(value)
    except:
        return None


def safe_bool(value) -> Optional[bool]:
    """Boolean ê°’ ë³€í™˜"""
    if pd.isna(value):
        return None
    if isinstance(value, bool):
        return value
    s = str(value).strip().lower()
    if s in ['yes', 'true', '1', 'y']:
        return True
    elif s in ['no', 'false', '0', 'n']:
        return False
    return None


def create_tdoc_instance(row: pd.Series, meeting_id: str, company_map: Dict[str, str]) -> dict:
    """Tdoc ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ê¸°ë³¸ í´ë˜ìŠ¤)

    Spec 7.3.9: ì†ì„± ë° ê´€ê³„ ë§¤í•‘
    """
    tdoc_number = safe_string(row.get('TDoc', ''))
    if not tdoc_number:
        return None

    # ê¸°ë³¸ ì†ì„±
    instance = {
        "@id": f"tdoc:{tdoc_number}",
        "@type": "tdoc:Tdoc",
        "tdoc:tdocNumber": tdoc_number,
        "tdoc:title": safe_string(row.get('Title', '')),
        "tdoc:type": safe_string(row.get('Type', '')),
        "tdoc:status": safe_string(row.get('TDoc Status', '')),
    }

    # ì„ íƒì  ì†ì„±
    if abstract := safe_string(row.get('Abstract', '')):
        instance["tdoc:abstract"] = abstract

    if for_value := safe_string(row.get('For', '')):
        instance["tdoc:for"] = for_value

    if reservation_date := safe_datetime(row.get('Reservation date', '')):
        instance["tdoc:reservationDate"] = reservation_date

    if uploaded_date := safe_datetime(row.get('Uploaded', '')):
        instance["tdoc:uploadedDate"] = uploaded_date

    if remarks := safe_string(row.get('Secretary Remarks', '')):
        instance["tdoc:secretaryRemarks"] = remarks

    # ê´€ê³„: submittedBy (Company), originatedFrom (WorkingGroup)
    # Issue #1, #5 í•´ê²°: WGì™€ Companyë¥¼ ë¶„ë¦¬
    companies, working_groups = parse_submitters(row.get('Source', ''), company_map)
    if companies:
        instance["submittedBy"] = [f"tdoc:company/{re.sub(r'[^a-zA-Z0-9]', '_', c)}" for c in companies]
    if working_groups:
        instance["originatedFrom"] = [f"tdoc:wg/{wg}" for wg in working_groups]

    # ê´€ê³„: hasContact (Contact)
    if contact_id := safe_string(row.get('Contact ID', '')):
        instance["hasContact"] = f"tdoc:contact/{re.sub(r'[^a-zA-Z0-9]', '_', contact_id)}"

    # ê´€ê³„: relatedTo (WorkItem)
    work_items = parse_work_items(row.get('Related WIs', ''))
    if work_items:
        instance["tdoc:relatedTo"] = [f"tdoc:workitem/{re.sub(r'[^a-zA-Z0-9_-]', '_', wi)}" for wi in work_items]

    # ê´€ê³„: belongsTo (AgendaItem)
    if agenda := safe_string(row.get('Agenda item', '')):
        instance["belongsTo"] = f"tdoc:agenda/{re.sub(r'[^a-zA-Z0-9.]', '_', agenda)}"

    # ê´€ê³„: targetRelease (Release)
    if release := safe_string(row.get('Release', '')):
        instance["tdoc:targetRelease"] = f"tdoc:release/{release.replace('-', '_')}"

    # ê´€ê³„: presentedAt (Meeting)
    instance["presentedAt"] = f"tdoc:meeting/{meeting_id.replace('#', '_')}"

    # ê´€ê³„: isRevisionOf, revisedTo, replyTo, replyIn (Tdoc â†’ Tdoc)
    if is_revision_of := safe_string(row.get('Is revision of', '')):
        instance["tdoc:isRevisionOf"] = f"tdoc:{is_revision_of}"

    if revised_to := safe_string(row.get('Revised to', '')):
        instance["tdoc:revisedTo"] = f"tdoc:{revised_to}"

    if reply_to := safe_string(row.get('Reply to', '')):
        instance["replyTo"] = f"tdoc:{reply_to}"

    if reply_in := safe_string(row.get('Reply in', '')):
        instance["tdoc:replyIn"] = f"tdoc:{reply_in}"

    return instance


def create_cr_instance(row: pd.Series, meeting_id: str, company_map: Dict[str, str]) -> dict:
    """CR ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Tdoc ìƒì† + ì¶”ê°€ ì†ì„±)

    Spec 7.3.10: CR ì „ìš© ì†ì„± ë° modifies ê´€ê³„
    """
    # ê¸°ë³¸ Tdoc ì†ì„±
    instance = create_tdoc_instance(row, meeting_id, company_map)
    if not instance:
        return None

    # í´ë˜ìŠ¤ ë³€ê²½
    instance["@type"] = "tdoc:CR"

    # CR ì „ìš© ì†ì„±
    if cr_number := safe_string(row.get('CR', '')):
        instance["tdoc:crNumber"] = cr_number

    if cr_category := safe_string(row.get('CR category', '')):
        instance["tdoc:crCategory"] = cr_category

    if clauses := safe_string(row.get('Clauses Affected', '')):
        instance["tdoc:clausesAffected"] = clauses

    if tsg_pack := safe_string(row.get('TSG CR Pack', '')):
        instance["tdoc:tsgCRPack"] = tsg_pack

    # Boolean ì†ì„± (ì˜í–¥ ë²”ìœ„)
    if (uicc := safe_bool(row.get('UICC', ''))) is not None:
        instance["tdoc:affectsUICC"] = uicc

    if (me := safe_bool(row.get('ME', ''))) is not None:
        instance["tdoc:affectsME"] = me

    if (ran := safe_bool(row.get('RAN', ''))) is not None:
        instance["tdoc:affectsRAN"] = ran

    if (cn := safe_bool(row.get('CN', ''))) is not None:
        instance["tdoc:affectsCN"] = cn

    # ê´€ê³„: modifies (Spec) - CR ì „ìš©
    if spec := safe_string(row.get('Spec', '')):
        instance["modifies"] = f"tdoc:spec/{spec.replace('.', '_')}"

    return instance


def create_ls_instance(row: pd.Series, meeting_id: str, company_map: Dict[str, str]) -> dict:
    """LS ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Tdoc ìƒì† + ì¶”ê°€ ì†ì„±)

    Spec 7.3.11: direction, sentTo, ccTo, originalLS
    """
    # ê¸°ë³¸ Tdoc ì†ì„±
    instance = create_tdoc_instance(row, meeting_id, company_map)
    if not instance:
        return None

    # í´ë˜ìŠ¤ ë³€ê²½
    instance["@type"] = "tdoc:LS"

    # direction ì¶”ì¶œ
    type_value = safe_string(row.get('Type', ''))
    if type_value == 'LS out':
        instance["tdoc:direction"] = "out"
    elif type_value == 'LS in':
        instance["tdoc:direction"] = "in"

    # ê´€ê³„: sentTo (WorkingGroup)
    to_wgs = parse_working_groups(row.get('To', ''))
    if to_wgs:
        instance["sentTo"] = [f"tdoc:wg/{re.sub(r'[^a-zA-Z0-9]', '_', wg)}" for wg in to_wgs]

    # ê´€ê³„: ccTo (WorkingGroup)
    cc_wgs = parse_working_groups(row.get('Cc', ''))
    if cc_wgs:
        instance["tdoc:ccTo"] = [f"tdoc:wg/{re.sub(r'[^a-zA-Z0-9]', '_', wg)}" for wg in cc_wgs]

    # ê´€ê³„: originalLS (LS in ì „ìš©)
    if instance.get("tdoc:direction") == "in":
        if original_ls := safe_string(row.get('Original LS', '')):
            instance["tdoc:originalLS"] = f"tdoc:{original_ls}"

    return instance


def process_file(filepath: Path, company_map: Dict[str, str]) -> Tuple[List[dict], Dict[str, int]]:
    """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
    meeting_id = extract_meeting_from_filename(filepath.name)
    if not meeting_id:
        return [], {}

    try:
        df = pd.read_excel(filepath, engine='openpyxl')
    except Exception as e:
        print(f"  Error loading {filepath.name}: {e}")
        return [], {}

    instances = []
    stats = {"Tdoc": 0, "CR": 0, "LS": 0}

    for _, row in df.iterrows():
        type_value = safe_string(row.get('Type', ''))
        doc_class = classify_tdoc_type(type_value)

        if doc_class == "CR":
            instance = create_cr_instance(row, meeting_id, company_map)
        elif doc_class == "LS":
            instance = create_ls_instance(row, meeting_id, company_map)
        else:
            instance = create_tdoc_instance(row, meeting_id, company_map)

        if instance:
            instances.append(instance)
            stats[doc_class] += 1

    return instances, stats


def main():
    """Phase C ë©”ì¸ ì‹¤í–‰"""
    print("=" * 60)
    print("Phase C: Tdoc/CR/LS ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
    print("=" * 60)

    # Company ì •ê·œí™” ë§µ ë¡œë“œ
    print("\n[1/4] Company ì •ê·œí™” ë§µ ë¡œë”©...")
    company_map = load_company_aliases()
    print(f"  ì •ê·œí™” ë§µ ë¡œë“œ: {len(company_map)}ê°œ ë³„ì¹­")

    # ì…ë ¥ íŒŒì¼ ëª©ë¡
    files = sorted(INPUT_DIR.glob("*.xlsx"))
    print(f"\n[2/4] ì…ë ¥ íŒŒì¼: {len(files)}ê°œ")

    # íŒŒì¼ë³„ ì²˜ë¦¬
    print("\n[3/4] ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
    all_instances = []
    total_stats = {"Tdoc": 0, "CR": 0, "LS": 0}

    for i, filepath in enumerate(files, 1):
        instances, stats = process_file(filepath, company_map)
        all_instances.extend(instances)

        for k, v in stats.items():
            total_stats[k] += v

        if i % 10 == 0 or i == len(files):
            print(f"  {i}/{len(files)} íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ...")

    # ì €ì¥
    print(f"\n[4/4] JSON-LD ì €ì¥...")
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    output = {
        **CONTEXT,
        "@graph": all_instances
    }

    output_path = OUTPUT_DIR / "tdocs.jsonld"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    # ìš”ì•½
    print("\n" + "=" * 60)
    print("Phase C ì™„ë£Œ")
    print("=" * 60)

    total = sum(total_stats.values())
    print(f"\nğŸ“Š ìƒì„± ê²°ê³¼:")
    print(f"  Tdoc (ì¼ë°˜): {total_stats['Tdoc']:>8}ê°œ")
    print(f"  CR:          {total_stats['CR']:>8}ê°œ")
    print(f"  LS:          {total_stats['LS']:>8}ê°œ")
    print(f"  {'â”€' * 22}")
    print(f"  ì´ê³„:        {total:>8}ê°œ")

    print(f"\nì¶œë ¥ íŒŒì¼: {output_path}")
    print(f"íŒŒì¼ í¬ê¸°: {output_path.stat().st_size / 1024 / 1024:.1f} MB")


if __name__ == "__main__":
    main()
