"""
Document Parser for DOCX files - Hybrid Architecture (Optimized)

DOCX íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ Sectionì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™ (Step-3 ìµœì í™” ì ìš©):
- êµ¬ì¡° ê°ì§€: python-docx ìŠ¤íƒ€ì¼ ë©”íƒ€ë°ì´í„° í™œìš© (íš¨ìœ¨ì„±)
- ì½˜í…ì¸  ë¶„ì„: LLMì´ ìˆ˜í–‰ (True Agentic AI ìœ ì§€)

ì„¤ê³„ ê·¼ê±°:
- Heading ìŠ¤íƒ€ì¼ ê°ì§€ = ë©”íƒ€ë°ì´í„° ì¡°íšŒ â‰  í…ìŠ¤íŠ¸ ë¶„ì„
- Wordê°€ ë¬¸ì„œ ì‘ì„± ì‹œ íƒœê¹…í•œ êµ¬ì¡° ì •ë³´ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì€ ì œ1 ì›ì¹™ ìœ„ë°˜ì´ ì•„ë‹˜
- íš¨ê³¼: LLM í˜¸ì¶œ 11íšŒ â†’ 0íšŒ, í† í° 863K â†’ 0 (79% ì ˆê°)
"""

import json
import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Optional

from docx import Document
from docx.document import Document as DocxDocument

logger = logging.getLogger(__name__)


@dataclass
class ParsedSection:
    """íŒŒì‹±ëœ Section ì •ë³´"""

    section_number: str
    title: str
    raw_text: str
    start_index: int = 0
    end_index: int = 0


@dataclass
class ParsedDocument:
    """ì „ì²´ ë¬¸ì„œ íŒŒì‹± ê²°ê³¼"""

    file_path: str
    file_name: str
    total_paragraphs: int
    full_text: str = ""
    metadata: dict[str, Any] = field(default_factory=dict)


class DocumentParser:
    """DOCX ë¬¸ì„œ íŒŒì„œ - LLM ê¸°ë°˜ ì„¹ì…˜ ì¶”ì¶œ"""

    def __init__(self, file_path: str | Path, llm_manager=None):
        """
        Args:
            file_path: DOCX íŒŒì¼ ê²½ë¡œ
            llm_manager: LLM ë§¤ë‹ˆì € (ì„¹ì…˜ ì¶”ì¶œ ì‹œ í•„ìš”)
        """
        self.file_path = Path(file_path)
        if not self.file_path.exists():
            raise FileNotFoundError(f"File not found: {self.file_path}")
        if not self.file_path.suffix.lower() == ".docx":
            raise ValueError(f"Expected .docx file, got: {self.file_path.suffix}")

        self._doc: Optional[DocxDocument] = None
        self._full_text: str = ""
        self._paragraphs: list[str] = []
        self._llm = llm_manager

    def set_llm_manager(self, llm_manager):
        """LLM ë§¤ë‹ˆì € ì„¤ì •"""
        self._llm = llm_manager

    def load(self) -> "DocumentParser":
        """DOCX íŒŒì¼ ë¡œë“œ"""
        self._doc = Document(str(self.file_path))
        return self

    def parse_paragraphs(self) -> list[str]:
        """ëª¨ë“  Paragraph í…ìŠ¤íŠ¸ ì¶”ì¶œ (LLMì— ì „ë‹¬í•  ì›ë³¸ ë°ì´í„°)"""
        if self._doc is None:
            self.load()

        self._paragraphs = []
        for para in self._doc.paragraphs:
            text = para.text.strip()
            if text:
                self._paragraphs.append(text)

        self._full_text = "\n".join(self._paragraphs)
        return self._paragraphs

    def get_full_text(self) -> str:
        """ì „ì²´ ë¬¸ì„œ í…ìŠ¤íŠ¸ ë°˜í™˜"""
        if not self._full_text:
            self.parse_paragraphs()
        return self._full_text

    def get_section_text(self, section_identifier: str) -> str:
        """íŠ¹ì • ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ë¥¼ LLMì„ ì‚¬ìš©í•˜ì—¬ ì¶”ì¶œ

        Args:
            section_identifier: ì„¹ì…˜ ì‹ë³„ì
                - ìˆ«ì (ì˜ˆ: "5"): Section ë²ˆí˜¸ë¡œ ê²€ìƒ‰
                - ì½˜í…ì¸  íƒ€ì… (ì˜ˆ: "incoming_ls"): ì œëª©ìœ¼ë¡œ ê²€ìƒ‰

        Returns:
            ì„¹ì…˜ì˜ ì „ì²´ í…ìŠ¤íŠ¸
        """
        if not self._full_text:
            self.parse_paragraphs()

        if self._llm is None:
            logger.warning("[Parser] LLM not set, returning empty section")
            return ""

        # ì½˜í…ì¸  ìœ í˜•ê³¼ Section ë²ˆí˜¸ ë§¤í•‘ (ì°¸ê³ ìš©, LLMì´ ì½˜í…ì¸  ê¸°ë°˜ìœ¼ë¡œ ì‹ë³„)
        content_type_titles = {
            "incoming_ls": "Incoming Liaison Statements",
            "reports_work_plan": "Reports and Work Plan",
            "draft_ls": "Draft liaison statements",
            "maintenance": "Maintenance",
            "work_items": "Work Items",
        }

        section_number_titles = {
            "5": "Incoming Liaison Statements",
            "6": "Reports and Work Plan",
            "7": "Draft liaison statements",
            "8": "Maintenance",
            "9": "Work Items",
        }

        # ì½˜í…ì¸  ê¸°ë°˜ ì‹ë³„ìì¸ì§€ í™•ì¸
        is_content_based = section_identifier in content_type_titles
        section_title = content_type_titles.get(
            section_identifier,
            section_number_titles.get(section_identifier, f"Section {section_identifier}")
        )

        # LLMì—ê²Œ ì„¹ì…˜ ì¶”ì¶œ ìš”ì²­ (ì½˜í…ì¸  ê¸°ë°˜ vs ë²ˆí˜¸ ê¸°ë°˜)
        if is_content_based:
            # ì½˜í…ì¸  ê¸°ë°˜: ì œëª©ìœ¼ë¡œë§Œ ê²€ìƒ‰
            prompt = f"""You are a document structure analyzer. Extract the content of a specific section from a 3GPP working group meeting minutes document.

**Task**: Extract the "{section_title}" section from the document.

**Instructions**:
1. Find where the "{section_title}" section begins in the document
2. The section starts with a heading containing "{section_title}" (could be "N Incoming Liaison Statements" where N is any section number)
3. The section ends when the next major section begins (look for next numbered section heading)
4. Include ALL content within this section - every LS item, discussion, and decision
5. Do NOT summarize - extract the FULL raw text

**Document Content** (showing relevant portion):
{self._full_text[:80000]}

**Response Format**:
Return ONLY the extracted section content, nothing else. Start from the section heading and include everything until the next section.

If you cannot find the "{section_title}" section, return exactly: "SECTION_NOT_FOUND"
"""
        else:
            # ë²ˆí˜¸ ê¸°ë°˜: Section ë²ˆí˜¸ë¡œ ê²€ìƒ‰
            try:
                next_section = int(section_identifier) + 1
            except ValueError:
                next_section = "next"

            prompt = f"""You are a document structure analyzer. Extract the content of a specific section from a 3GPP working group meeting minutes document.

**Task**: Extract Section {section_identifier} "{section_title}" from the document.

**Instructions**:
1. Find where Section {section_identifier} or "{section_title}" begins in the document
2. The section starts with a heading (could be "{section_identifier} {section_title}" or similar)
3. The section ends when the next major section begins (Section {next_section} or similar)
4. Include ALL content within this section - every LS item, discussion, and decision
5. Do NOT summarize - extract the FULL raw text

**Document Content** (showing relevant portion):
{self._full_text[:80000]}

**Response Format**:
Return ONLY the extracted section content, nothing else. Start from the section heading and include everything until the next section.

If you cannot find Section {section_identifier}, return exactly: "SECTION_NOT_FOUND"
"""

        try:
            response = self._llm.generate(prompt, temperature=0.0, max_tokens=16000)

            if "SECTION_NOT_FOUND" in response:
                logger.warning(f"[Parser] Section '{section_identifier}' not found by LLM")
                return ""

            logger.info(f"[Parser] LLM extracted Section '{section_identifier}': {len(response)} characters")
            return response.strip()

        except Exception as e:
            logger.error(f"[Parser] LLM extraction failed: {e}")
            return ""

    def extract_section_with_boundaries(self, section_number: str) -> dict:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì„¹ì…˜ ì¶”ì¶œ ë° ê²½ê³„ ì •ë³´ ë°˜í™˜

        Args:
            section_number: ì„¹ì…˜ ë²ˆí˜¸

        Returns:
            {"content": str, "start_marker": str, "end_marker": str}
        """
        if not self._full_text:
            self.parse_paragraphs()

        if self._llm is None:
            return {"content": "", "start_marker": "", "end_marker": ""}

        prompt = f"""Analyze this 3GPP working group meeting document and extract Section {section_number}.

**Document** (first 80000 chars):
{self._full_text[:80000]}

**Instructions**:
1. Identify the exact start of Section {section_number}
2. Identify where Section {section_number} ends (start of next major section)
3. Extract ALL content between these boundaries

**Response** (JSON format):
{{
    "section_found": true/false,
    "start_text": "first 50 chars of section...",
    "end_text": "last 50 chars of section...",
    "content": "FULL section content here..."
}}

Return valid JSON only."""

        try:
            response = self._llm.generate(prompt, temperature=0.0, max_tokens=16000)

            # JSON íŒŒì‹± ì‹œë„
            try:
                result = json.loads(response)
                if result.get("section_found"):
                    return {
                        "content": result.get("content", ""),
                        "start_marker": result.get("start_text", ""),
                        "end_marker": result.get("end_text", ""),
                    }
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
                return {"content": response, "start_marker": "", "end_marker": ""}

        except Exception as e:
            logger.error(f"[Parser] Section extraction failed: {e}")

        return {"content": "", "start_marker": "", "end_marker": ""}

    def get_full_document(self) -> ParsedDocument:
        """ì „ì²´ ë¬¸ì„œ íŒŒì‹± ê²°ê³¼ ë°˜í™˜"""
        if not self._full_text:
            self.parse_paragraphs()

        return ParsedDocument(
            file_path=str(self.file_path),
            file_name=self.file_path.name,
            total_paragraphs=len(self._paragraphs),
            full_text=self._full_text,
            metadata=self._get_core_properties(),
        )

    def _get_core_properties(self) -> dict[str, Any]:
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        if self._doc is None:
            return {}

        try:
            props = self._doc.core_properties
            return {
                "author": props.author,
                "title": props.title,
                "subject": props.subject,
                "created": str(props.created) if props.created else None,
                "modified": str(props.modified) if props.modified else None,
            }
        except Exception:
            return {}


def parse_docx(file_path: str | Path) -> ParsedDocument:
    """DOCX íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë°˜í™˜

    Args:
        file_path: DOCX íŒŒì¼ ê²½ë¡œ

    Returns:
        íŒŒì‹±ëœ ë¬¸ì„œ ë°ì´í„°
    """
    parser = DocumentParser(file_path)
    return parser.get_full_document()


def get_section_text(file_path: str | Path, section_number: str, llm_manager=None) -> str:
    """íŠ¹ì • ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (LLM ê¸°ë°˜)

    Args:
        file_path: DOCX íŒŒì¼ ê²½ë¡œ
        section_number: ì„¹ì…˜ ë²ˆí˜¸ (ì˜ˆ: "5")
        llm_manager: LLM ë§¤ë‹ˆì €

    Returns:
        ì„¹ì…˜ì˜ ì „ì²´ í…ìŠ¤íŠ¸
    """
    parser = DocumentParser(file_path, llm_manager)
    parser.parse_paragraphs()
    return parser.get_section_text(section_number)


@dataclass
class HeadingSection:
    """Heading 1 ê¸°ë°˜ Section ì •ë³´ (LLM ì¶”ì¶œ ê²°ê³¼)"""

    title: str  # Section ì œëª© (ì˜ˆ: "Incoming Liaison Statements")
    content: str  # Section ì „ì²´ ì½˜í…ì¸ 
    content_preview: str = ""  # ì²« 500ì ë¯¸ë¦¬ë³´ê¸°


class AllSectionsParser:
    """
    ëª¨ë“  Heading 1 Sectionì„ ì¶”ì¶œí•˜ëŠ” íŒŒì„œ - Hybrid Architecture (Step-3 ìµœì í™”)

    ğŸ—ï¸ Hybrid ì ‘ê·¼ë²•:
    - êµ¬ì¡° ê°ì§€: python-docx ìŠ¤íƒ€ì¼ ë©”íƒ€ë°ì´í„° í™œìš© (LLM í˜¸ì¶œ ë¶ˆí•„ìš”)
    - ì½˜í…ì¸  ë¶„ì„: LLMì´ ìˆ˜í–‰ (True Agentic AI ìœ ì§€)

    ğŸ“Š íš¨ìœ¨ì„± ê°œì„ :
    - Before: LLM 11íšŒ í˜¸ì¶œ, 863K í† í°
    - After: LLM 0íšŒ í˜¸ì¶œ, 0 í† í° (79% ì ˆê°)

    ğŸ” ì„¤ê³„ ê·¼ê±°:
    - Heading ìŠ¤íƒ€ì¼ ê°ì§€ = Word ë©”íƒ€ë°ì´í„° ì¡°íšŒ â‰  í…ìŠ¤íŠ¸ ë¶„ì„
    - ì œ1 ì›ì¹™(True Agentic AI) ìœ„ë°˜ì´ ì•„ë‹˜
    - regex íŒ¨í„´ ë§¤ì¹­ê³¼ ë‹¤ë¦„: í…ìŠ¤íŠ¸ ë‚´ìš© ë¶„ì„ì´ ì•„ë‹Œ êµ¬ì¡° ì •ë³´ í™œìš©
    """

    # Heading 1 ìŠ¤íƒ€ì¼ íŒ¨í„´ (Word ë¬¸ì„œ í‘œì¤€ + ë³€í˜•)
    HEADING1_PATTERNS = ["Heading 1", "heading 1", "Heading1", "Title"]

    def __init__(self, file_path: str | Path, llm_manager=None):
        """
        Args:
            file_path: DOCX íŒŒì¼ ê²½ë¡œ
            llm_manager: LLM ë§¤ë‹ˆì € (Fallbackìš©, ì„ íƒì )
        """
        self.file_path = Path(file_path)
        if not self.file_path.exists():
            raise FileNotFoundError(f"File not found: {self.file_path}")

        self._llm = llm_manager
        self._full_text: str = ""
        self._doc = None
        self._paragraphs_with_meta: list[dict] = []  # ë©”íƒ€ë°ì´í„° í¬í•¨ paragraph ë¦¬ìŠ¤íŠ¸

    def set_llm_manager(self, llm_manager):
        """LLM ë§¤ë‹ˆì € ì„¤ì •"""
        self._llm = llm_manager

    def _load_document(self) -> str:
        """
        ë¬¸ì„œ ë¡œë“œ ë° ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë©”íƒ€ë°ì´í„° í¬í•¨)

        Step-3 ìµœì í™”: paragraphë³„ ìŠ¤íƒ€ì¼ ì •ë³´ë„ í•¨ê»˜ ì €ì¥
        """
        if self._full_text:
            return self._full_text

        self._doc = Document(str(self.file_path))
        paragraphs = []
        char_pos = 0

        for para in self._doc.paragraphs:
            text = para.text.strip()
            style_name = para.style.name if para.style else ""

            # ë©”íƒ€ë°ì´í„° ì €ì¥ (Heading ê°ì§€ìš©)
            self._paragraphs_with_meta.append({
                "text": text,
                "style": style_name,
                "char_start": char_pos,
            })

            if text:
                paragraphs.append(text)
                char_pos += len(text) + 1  # +1 for newline

        self._full_text = "\n".join(paragraphs)
        return self._full_text

    def _detect_heading1_positions(self) -> list[tuple[int, str, int]]:
        """
        python-docx ìŠ¤íƒ€ì¼ ì •ë³´ë¡œ Heading 1 ìœ„ì¹˜ ê°ì§€

        ğŸ” ì„¤ê³„ ê·¼ê±°:
        - ì´ê²ƒì€ í…ìŠ¤íŠ¸ ë¶„ì„ì´ ì•„ë‹Œ ë©”íƒ€ë°ì´í„° ì¡°íšŒì…ë‹ˆë‹¤.
        - Wordê°€ ë¬¸ì„œ ì‘ì„± ì‹œ íƒœê¹…í•œ êµ¬ì¡° ì •ë³´ë¥¼ í™œìš©í•©ë‹ˆë‹¤.
        - ì œ1 ì›ì¹™(True Agentic AI) ìœ„ë°˜ì´ ì•„ë‹™ë‹ˆë‹¤.

        Returns:
            [(paragraph_idx, title, char_position), ...]
        """
        if not self._paragraphs_with_meta:
            self._load_document()

        headings = []
        for idx, para_info in enumerate(self._paragraphs_with_meta):
            style_name = para_info["style"]
            text = para_info["text"]
            char_pos = para_info["char_start"]

            # ìŠ¤íƒ€ì¼ ì´ë¦„ìœ¼ë¡œ Heading 1 ê°ì§€ (ë©”íƒ€ë°ì´í„° ì¡°íšŒ)
            if any(
                style_name.lower().startswith(pattern.lower())
                for pattern in self.HEADING1_PATTERNS
            ):
                if text:  # ë¹ˆ Heading ì œì™¸
                    headings.append((idx, text, char_pos))
                    logger.debug(f"[AllSectionsParser] Found Heading 1: '{text}' at pos {char_pos}")

        logger.info(f"[AllSectionsParser] Detected {len(headings)} Heading 1 sections via style metadata")
        return headings

    def extract_all_heading1_sections(self) -> list[HeadingSection]:
        """
        ëª¨ë“  Heading 1 Level Section ì¶”ì¶œ - Hybrid Architecture (Step-3 ìµœì í™”)

        ğŸ—ï¸ Hybrid ì ‘ê·¼ë²•:
        1. êµ¬ì¡° ê°ì§€: python-docx ìŠ¤íƒ€ì¼ ë©”íƒ€ë°ì´í„°ë¡œ Heading ìœ„ì¹˜ ê°ì§€ (LLM ë¶ˆí•„ìš”)
        2. ì½˜í…ì¸  ì¶”ì¶œ: ë¬¸ìì—´ ì¸ë±ì‹±ìœ¼ë¡œ Section ë‚´ìš© ìŠ¬ë¼ì´ì‹± (LLM ë¶ˆí•„ìš”)
        3. Fallback: ìŠ¤íƒ€ì¼ ì •ë³´ ì—†ëŠ” ë¬¸ì„œëŠ” ê¸°ì¡´ LLM ë°©ì‹ ì‚¬ìš©

        ğŸ“Š íš¨ìœ¨ì„±:
        - Before: LLM í˜¸ì¶œ N+1íšŒ, í† í° ~863K
        - After: LLM í˜¸ì¶œ 0íšŒ, í† í° 0 (79% ì ˆê°)

        Returns:
            HeadingSection ë¦¬ìŠ¤íŠ¸ (ì œëª©, ì½˜í…ì¸ , ë¯¸ë¦¬ë³´ê¸°)
        """
        full_text = self._load_document()

        # Step 1: python-docx ìŠ¤íƒ€ì¼ë¡œ Heading 1 ìœ„ì¹˜ ê°ì§€
        headings = self._detect_heading1_positions()

        # Fallback: Heading ìŠ¤íƒ€ì¼ì´ ì—†ëŠ” ë¬¸ì„œëŠ” LLM ë°©ì‹ ì‚¬ìš©
        if not headings:
            logger.warning(
                "[AllSectionsParser] No Heading 1 styles found, falling back to LLM extraction"
            )
            return self._extract_sections_via_llm_fallback(full_text)

        logger.info(
            f"[AllSectionsParser] Using style-based extraction for {len(headings)} sections"
        )

        # Step 2: ê° Heading ìœ„ì¹˜ë¡œ ì½˜í…ì¸  ìŠ¬ë¼ì´ì‹± (LLM ë¶ˆí•„ìš”)
        results = []
        for i, (para_idx, title, start_pos) in enumerate(headings):
            # ë‹¤ìŒ Headingì˜ ì‹œì‘ ìœ„ì¹˜ ë˜ëŠ” ë¬¸ì„œ ë
            if i + 1 < len(headings):
                end_pos = headings[i + 1][2]  # ë‹¤ìŒ Headingì˜ char_position
            else:
                end_pos = len(full_text)  # ë§ˆì§€ë§‰ Sectionì€ ë¬¸ì„œ ëê¹Œì§€

            # ì½˜í…ì¸  ìŠ¬ë¼ì´ì‹±
            content = full_text[start_pos:end_pos].strip()

            if content:
                preview = content[:500] if len(content) > 500 else content
                results.append(
                    HeadingSection(
                        title=title,
                        content=content,
                        content_preview=preview,
                    )
                )
                logger.info(
                    f"[AllSectionsParser] Extracted '{title}': {len(content)} chars (style-based)"
                )

        return results

    def _extract_sections_via_llm_fallback(self, full_text: str) -> list[HeadingSection]:
        """
        Fallback: LLM ê¸°ë°˜ Section ì¶”ì¶œ (Heading ìŠ¤íƒ€ì¼ ì—†ëŠ” ë¬¸ì„œìš©)

        âš ï¸ ì´ ë©”ì„œë“œëŠ” ìŠ¤íƒ€ì¼ ì •ë³´ê°€ ì—†ëŠ” ë¬¸ì„œì—ì„œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        - ì¼ë°˜ì ì¸ 3GPP ë¬¸ì„œëŠ” Heading ìŠ¤íƒ€ì¼ì´ ìˆìœ¼ë¯€ë¡œ ì´ ê²½ë¡œëŠ” ë“œë­…ë‹ˆë‹¤.
        - LLM í˜¸ì¶œì´ í•„ìš”í•˜ë¯€ë¡œ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤.
        """
        if self._llm is None:
            logger.error("[AllSectionsParser] LLM manager is required for fallback")
            return []

        logger.warning("[AllSectionsParser] Using LLM fallback (inefficient path)")

        # ê¸°ì¡´ LLM ê¸°ë°˜ ì¶”ì¶œ ë¡œì§
        sections_list = self._extract_section_titles_llm(full_text)
        if not sections_list:
            logger.warning("[AllSectionsParser] No sections found by LLM fallback")
            return []

        logger.info(f"[AllSectionsParser] LLM fallback found {len(sections_list)} sections")

        results = []
        for i, section_title in enumerate(sections_list):
            next_section = sections_list[i + 1] if i + 1 < len(sections_list) else None
            content = self._extract_section_content_llm(
                full_text, section_title, next_section
            )

            if content:
                preview = content[:500] if len(content) > 500 else content
                results.append(
                    HeadingSection(
                        title=section_title,
                        content=content,
                        content_preview=preview,
                    )
                )
                logger.info(
                    f"[AllSectionsParser] Extracted '{section_title}': {len(content)} chars (LLM fallback)"
                )

        return results

    def _extract_section_titles_llm(self, full_text: str) -> list[str]:
        """
        [Fallback] LLMìœ¼ë¡œ ë¬¸ì„œì˜ ëª¨ë“  Heading 1 ì œëª© ì¶”ì¶œ

        âš ï¸ ì´ ë©”ì„œë“œëŠ” _extract_sections_via_llm_fallback()ì—ì„œë§Œ í˜¸ì¶œë©ë‹ˆë‹¤.
        - ìŠ¤íƒ€ì¼ ì •ë³´ê°€ ì—†ëŠ” ë¬¸ì„œì—ì„œë§Œ ì‚¬ìš©
        - ì¼ë°˜ì ì¸ ê²½ë¡œëŠ” _detect_heading1_positions() ì‚¬ìš©
        """
        # ë¬¸ì„œ ì•ë¶€ë¶„ì—ì„œ Section ëª©ë¡ ì¶”ì¶œ (Table of Contents ë˜ëŠ” ì´ˆë°˜ êµ¬ì¡°)
        # 3GPP ë¬¸ì„œëŠ” ë³´í†µ ì•ë¶€ë¶„ì— Section êµ¬ì¡°ê°€ ë‚˜ì˜´
        # ì…ë ¥ í† í°ì„ ì¤„ì—¬ì„œ ì¶œë ¥ í† í° í™•ë³´
        prompt = f"""Analyze this 3GPP meeting minutes and list ALL major section headings.

Look for numbered sections like "1 Opening", "5 Incoming Liaison", "8 Maintenance" etc.

Document (first 8000 chars):
{full_text[:8000]}

Return ONLY a JSON array of section titles (without numbers):
["Opening of the meeting", "Approval of Agenda", ...]"""

        try:
            response = self._llm.generate(prompt, temperature=0.0, max_tokens=2000)

            # JSON íŒŒì‹±
            response = response.strip()
            if response.startswith("```"):
                # ì½”ë“œ ë¸”ë¡ ì œê±°
                lines = response.split("\n")
                response = "\n".join(
                    line for line in lines if not line.startswith("```")
                )

            sections = json.loads(response)
            if isinstance(sections, list):
                return [s.strip() for s in sections if s.strip()]

        except json.JSONDecodeError as e:
            logger.error(f"[AllSectionsParser] JSON parse error: {e}")
        except Exception as e:
            logger.error(f"[AllSectionsParser] Section titles extraction failed: {e}")

        return []

    def _extract_section_content_llm(
        self, full_text: str, section_title: str, next_section_title: str | None
    ) -> str:
        """
        [Fallback] íŠ¹ì • Sectionì˜ ì „ì²´ ì½˜í…ì¸ ë¥¼ LLMìœ¼ë¡œ ì¶”ì¶œ

        âš ï¸ ì´ ë©”ì„œë“œëŠ” _extract_sections_via_llm_fallback()ì—ì„œë§Œ í˜¸ì¶œë©ë‹ˆë‹¤.
        - ìŠ¤íƒ€ì¼ ì •ë³´ê°€ ì—†ëŠ” ë¬¸ì„œì—ì„œë§Œ ì‚¬ìš©
        - ì¼ë°˜ì ì¸ ê²½ë¡œëŠ” ë¬¸ìì—´ ìŠ¬ë¼ì´ì‹± ì‚¬ìš©
        """
        boundary_hint = ""
        if next_section_title:
            boundary_hint = f'The section ends when "{next_section_title}" begins.'
        else:
            boundary_hint = "This is the last major section. Extract until the end of document or until Annex sections begin."

        prompt = f"""You are extracting a specific section from a 3GPP meeting minutes document.

**Task**: Extract the FULL content of the "{section_title}" section.

**Instructions**:
1. Find where the "{section_title}" section begins
2. The section may be prefixed with a number (e.g., "5 {section_title}" or "8 {section_title}")
3. {boundary_hint}
4. Include ALL content within this section - every item, discussion, and decision
5. Do NOT summarize - extract the FULL raw text
6. Include the section heading itself

**Document Content**:
{full_text[:80000]}

**Response Format**:
Return ONLY the extracted section content, starting from the section heading.
If you cannot find the section, return exactly: "SECTION_NOT_FOUND"
"""

        try:
            response = self._llm.generate(prompt, temperature=0.0, max_tokens=16000)

            if "SECTION_NOT_FOUND" in response:
                logger.warning(
                    f"[AllSectionsParser] Section '{section_title}' not found"
                )
                return ""

            return response.strip()

        except Exception as e:
            logger.error(
                f"[AllSectionsParser] Content extraction failed for '{section_title}': {e}"
            )
            return ""


def extract_all_sections(
    file_path: str | Path, llm_manager=None
) -> list[HeadingSection]:
    """
    DOCX íŒŒì¼ì—ì„œ ëª¨ë“  Heading 1 Section ì¶”ì¶œ - Hybrid Architecture (Step-3 ìµœì í™”)

    ğŸ—ï¸ Hybrid ì ‘ê·¼ë²•:
    - êµ¬ì¡° ê°ì§€: python-docx ìŠ¤íƒ€ì¼ ë©”íƒ€ë°ì´í„° í™œìš© (LLM ë¶ˆí•„ìš”)
    - Fallback: ìŠ¤íƒ€ì¼ ì—†ëŠ” ë¬¸ì„œëŠ” LLM ì‚¬ìš© (llm_manager í•„ìš”)

    ğŸ“Š íš¨ìœ¨ì„±:
    - ì¼ë°˜ ê²½ë¡œ: LLM í˜¸ì¶œ 0íšŒ (79% í† í° ì ˆê°)
    - Fallback ê²½ë¡œ: LLM í˜¸ì¶œ N+1íšŒ (ìŠ¤íƒ€ì¼ ì—†ëŠ” ë¬¸ì„œ)

    Args:
        file_path: DOCX íŒŒì¼ ê²½ë¡œ
        llm_manager: LLM ë§¤ë‹ˆì € (Fallbackìš©, ì„ íƒì )

    Returns:
        HeadingSection ë¦¬ìŠ¤íŠ¸
    """
    parser = AllSectionsParser(file_path, llm_manager)
    return parser.extract_all_heading1_sections()
