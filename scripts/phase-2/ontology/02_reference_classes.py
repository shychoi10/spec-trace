#!/usr/bin/env python3
"""
Phase B: Reference í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

Spec ê¸°ë°˜: docs/phase-2/specs/tdoc-ontology-spec.md Step 7.3
ì…ë ¥: ontology/input/meetings/RAN1/*.xlsx (59ê°œ íŒŒì¼)
ì¶œë ¥: ontology/output/instances/*.jsonld

ìƒì„± í´ë˜ìŠ¤ (8ê°œ):
1. Meeting - íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
2. Release - Release ì»¬ëŸ¼ ê³ ìœ ê°’
3. Company - company_aliases_significant.json (222ê°œ)
4. Contact - Contact, Contact ID ì»¬ëŸ¼
5. WorkItem - Related WIs ì»¬ëŸ¼
6. AgendaItem - Agenda item, Agenda item description ì»¬ëŸ¼
7. Spec - Spec ì»¬ëŸ¼
8. WorkingGroup - To, Cc ì»¬ëŸ¼
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple, Any
from collections import defaultdict
import pandas as pd
from concurrent.futures import ProcessPoolExecutor
import warnings

warnings.filterwarnings('ignore')

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
INPUT_DIR = BASE_DIR / "input" / "meetings" / "RAN1"
INTERMEDIATE_DIR = BASE_DIR / "intermediate"
OUTPUT_DIR = BASE_DIR / "output" / "instances"

# JSON-LD ì»¨í…ìŠ¤íŠ¸
CONTEXT = {
    "@context": {
        "tdoc": "http://3gpp.org/ontology/tdoc#",
        "dc": "http://purl.org/dc/elements/1.1/",
        "foaf": "http://xmlns.com/foaf/0.1/",
        "xsd": "http://www.w3.org/2001/XMLSchema#"
    }
}


def load_excel_file(filepath: Path) -> pd.DataFrame:
    """Excel íŒŒì¼ ë¡œë“œ"""
    try:
        df = pd.read_excel(filepath, engine='openpyxl')
        return df
    except Exception as e:
        print(f"Error loading {filepath.name}: {e}")
        return pd.DataFrame()


def extract_meeting_from_filename(filename: str) -> Tuple[str, str]:
    """íŒŒì¼ëª…ì—ì„œ Meeting ì •ë³´ ì¶”ì¶œ

    Spec 7.3.1: ID = {WG}#{íšŒì°¨} (ì˜ˆ: RAN1#120)

    íŒŒì¼ëª… íŒ¨í„´:
    - TDoc_List_TSGR1_100.xlsx â†’ RAN1#100
    - TDoc_List_TSGR1_100_e.xlsx â†’ RAN1#100-e
    - TDoc_List_TSGR1_100b_e.xlsx â†’ RAN1#100b-e
    - TDoc_List_TSGR1_101-e.xlsx â†’ RAN1#101-e
    """
    # TSGR1 = TSG RAN1 = RAN1
    match = re.search(r'TSGR1_(\d+)([a-z]?)(?:[-_]?(e))?', filename, re.IGNORECASE)
    if match:
        meeting_num = match.group(1)
        letter_suffix = match.group(2) if match.group(2) else ""
        e_suffix = match.group(3) if match.group(3) else ""

        # ì¡°í•©: 100 â†’ RAN1#100, 100b â†’ RAN1#100b, 100_e â†’ RAN1#100-e, 100b_e â†’ RAN1#100b-e
        suffix = letter_suffix
        if e_suffix:
            suffix = f"{letter_suffix}-e"

        meeting_id = f"RAN1#{meeting_num}{suffix}"
        return meeting_id, "RAN1"
    return None, None


def parse_work_items(value: str) -> List[str]:
    """Related WIs ì»¬ëŸ¼ íŒŒì‹±

    Spec 7.3.5: ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ì—¬ ë³µìˆ˜ WorkItem ìƒì„±
    """
    if pd.isna(value) or not str(value).strip():
        return []

    # ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ê³  ê³µë°± ì œê±°
    items = [item.strip() for item in str(value).split(',')]
    return [item for item in items if item and item not in ['', 'nan', 'NaN']]


def parse_working_groups(value: str) -> List[str]:
    """To/Cc ì»¬ëŸ¼ íŒŒì‹±

    Spec 7.3.8: ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ì—¬ ë³µìˆ˜ WorkingGroup ìƒì„±
    """
    if pd.isna(value) or not str(value).strip():
        return []

    # ì‰¼í‘œë¡œ ë¶„ë¦¬
    items = [item.strip() for item in str(value).split(',')]

    # ìœ íš¨í•œ Working Groupë§Œ í•„í„°ë§
    # 3GPP WG íŒ¨í„´: RAN1, SA2, CT1, TSG RAN ë“±
    valid_wgs = []
    for item in items:
        if item and item not in ['', 'nan', 'NaN']:
            # ê¸°ë³¸ ì •ë¦¬
            item = item.strip()
            if item:
                valid_wgs.append(item)

    return valid_wgs


def generate_meetings(files: List[Path]) -> Dict[str, dict]:
    """Meeting ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Spec 7.3.1: íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
    ì†ì„±: meetingNumber, workingGroup, canonicalMeetingNumber, meetingNumberInt

    canonicalMeetingNumber: -e suffix ì œê±° (COVID e-meeting ë§¤ì¹­ìš©)
    ì˜ˆ: RAN1#101-e â†’ RAN1#101, RAN1#112bis-e â†’ RAN1#112bis

    meetingNumberInt: ìˆ«ì ì •ë ¬ìš© (Spec CQ ê²°ê³¼ ê·œì¹™)
    ì˜ˆ: RAN1#122 â†’ 122, RAN1#122b â†’ 122
    """
    meetings = {}

    for filepath in files:
        meeting_id, wg = extract_meeting_from_filename(filepath.name)
        if meeting_id and meeting_id not in meetings:
            # canonicalMeetingNumber: -e suffix ì œê±° (Spec Section 5.6, 7.3.1)
            canonical = meeting_id[:-2] if meeting_id.endswith('-e') else meeting_id

            # meetingNumberInt: ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ (ì •ë ¬ìš©)
            # RAN1#122 â†’ 122, RAN1#122b â†’ 122, RAN1#84bis â†’ 84
            num_match = re.search(r'#(\d+)', meeting_id)
            meeting_num_int = int(num_match.group(1)) if num_match else 0

            meetings[meeting_id] = {
                "@id": f"tdoc:meeting/{meeting_id.replace('#', '_')}",
                "@type": "tdoc:Meeting",
                "tdoc:meetingNumber": meeting_id,
                "tdoc:canonicalMeetingNumber": canonical,
                "tdoc:meetingNumberInt": meeting_num_int,
                "tdoc:workingGroup": wg
            }

    return meetings


def generate_releases(all_data: List[pd.DataFrame]) -> Dict[str, dict]:
    """Release ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Spec 7.3.2: Release ì»¬ëŸ¼ ê³ ìœ ê°’
    ì†ì„±: releaseName
    """
    releases = {}

    for df in all_data:
        if 'Release' not in df.columns:
            continue

        for release in df['Release'].dropna().unique():
            release = str(release).strip()
            if release and release not in releases:
                releases[release] = {
                    "@id": f"tdoc:release/{release.replace('-', '_')}",
                    "@type": "tdoc:Release",
                    "tdoc:releaseName": release
                }

    return releases


def generate_companies(aliases_path: Path) -> Dict[str, dict]:
    """Company ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Spec 7.3.3: company_aliases_significant.json ì‚¬ìš©
    ì†ì„±: companyName
    """
    companies = {}

    with open(aliases_path, 'r', encoding='utf-8') as f:
        aliases = json.load(f)

    for canonical, data in aliases.items():
        # ID ìƒì„±: íŠ¹ìˆ˜ë¬¸ì ì œê±°
        company_id = re.sub(r'[^a-zA-Z0-9]', '_', canonical)
        companies[canonical] = {
            "@id": f"tdoc:company/{company_id}",
            "@type": ["tdoc:Company", "foaf:Organization"],
            "tdoc:companyName": canonical,
            "tdoc:aliases": data.get("aliases", [])
        }

    return companies


def generate_contacts(all_data: List[pd.DataFrame]) -> Dict[str, dict]:
    """Contact ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Spec 7.3.4: Contact, Contact ID ì»¬ëŸ¼
    ì†ì„±: contactName, contactId
    """
    contacts = {}

    for df in all_data:
        if 'Contact' not in df.columns or 'Contact ID' not in df.columns:
            continue

        for _, row in df.iterrows():
            contact_name = row.get('Contact', '')
            contact_id = row.get('Contact ID', '')

            if pd.isna(contact_name) or not str(contact_name).strip():
                continue

            contact_name = str(contact_name).strip()
            contact_id = str(contact_id).strip() if not pd.isna(contact_id) else ""

            # Contact IDë¥¼ í‚¤ë¡œ ì‚¬ìš© (ê³ ìœ )
            key = contact_id if contact_id else contact_name

            if key and key not in contacts:
                contacts[key] = {
                    "@id": f"tdoc:contact/{re.sub(r'[^a-zA-Z0-9]', '_', key)}",
                    "@type": ["tdoc:Contact", "foaf:Person"],
                    "tdoc:contactName": contact_name,
                    "tdoc:contactId": contact_id
                }

    return contacts


def generate_work_items(all_data: List[pd.DataFrame]) -> Dict[str, dict]:
    """WorkItem ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Spec 7.3.5: Related WIs ì»¬ëŸ¼
    ì†ì„±: workItemCode
    """
    work_items = {}

    for df in all_data:
        if 'Related WIs' not in df.columns:
            continue

        for value in df['Related WIs'].dropna():
            items = parse_work_items(value)
            for item in items:
                if item not in work_items:
                    work_items[item] = {
                        "@id": f"tdoc:workitem/{re.sub(r'[^a-zA-Z0-9_-]', '_', item)}",
                        "@type": "tdoc:WorkItem",
                        "tdoc:workItemCode": item
                    }

    return work_items


def generate_agenda_items(all_data: List[pd.DataFrame]) -> Dict[str, dict]:
    """AgendaItem ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Spec 7.3.6: Agenda item, Agenda item description ì»¬ëŸ¼
    ì†ì„±: agendaNumber, agendaDescription
    """
    agenda_items = {}

    for df in all_data:
        if 'Agenda item' not in df.columns:
            continue

        for _, row in df.iterrows():
            agenda_num = row.get('Agenda item', '')
            agenda_desc = row.get('Agenda item description', '')

            if pd.isna(agenda_num) or not str(agenda_num).strip():
                continue

            agenda_num = str(agenda_num).strip()
            agenda_desc = str(agenda_desc).strip() if not pd.isna(agenda_desc) else ""

            if agenda_num not in agenda_items:
                agenda_items[agenda_num] = {
                    "@id": f"tdoc:agenda/{re.sub(r'[^a-zA-Z0-9.]', '_', agenda_num)}",
                    "@type": "tdoc:AgendaItem",
                    "tdoc:agendaNumber": agenda_num,
                    "tdoc:agendaDescription": agenda_desc
                }
            elif not agenda_items[agenda_num].get("tdoc:agendaDescription") and agenda_desc:
                # ê¸°ì¡´ì— descriptionì´ ì—†ê³  ìƒˆë¡œ ë°œê²¬ë˜ë©´ ì—…ë°ì´íŠ¸
                agenda_items[agenda_num]["tdoc:agendaDescription"] = agenda_desc

    return agenda_items


def generate_specs(all_data: List[pd.DataFrame]) -> Dict[str, dict]:
    """Spec ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Spec 7.3.7: Spec ì»¬ëŸ¼
    ì†ì„±: specNumber
    """
    specs = {}

    for df in all_data:
        if 'Spec' not in df.columns:
            continue

        for value in df['Spec'].dropna():
            spec_num = str(value).strip()
            if spec_num and spec_num not in specs:
                specs[spec_num] = {
                    "@id": f"tdoc:spec/{spec_num.replace('.', '_')}",
                    "@type": "tdoc:Spec",
                    "tdoc:specNumber": spec_num
                }

    return specs


def generate_working_groups(all_data: List[pd.DataFrame]) -> Dict[str, dict]:
    """WorkingGroup ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Spec 7.3.8: To, Cc ì»¬ëŸ¼
    ì†ì„±: wgName
    """
    working_groups = {}

    for df in all_data:
        # To ì»¬ëŸ¼
        if 'To' in df.columns:
            for value in df['To'].dropna():
                wgs = parse_working_groups(value)
                for wg in wgs:
                    if wg not in working_groups:
                        working_groups[wg] = {
                            "@id": f"tdoc:wg/{re.sub(r'[^a-zA-Z0-9]', '_', wg)}",
                            "@type": "tdoc:WorkingGroup",
                            "tdoc:wgName": wg
                        }

        # Cc ì»¬ëŸ¼
        if 'Cc' in df.columns:
            for value in df['Cc'].dropna():
                wgs = parse_working_groups(value)
                for wg in wgs:
                    if wg not in working_groups:
                        working_groups[wg] = {
                            "@id": f"tdoc:wg/{re.sub(r'[^a-zA-Z0-9]', '_', wg)}",
                            "@type": "tdoc:WorkingGroup",
                            "tdoc:wgName": wg
                        }

    return working_groups


def save_jsonld(data: Dict[str, dict], output_path: Path, class_name: str):
    """JSON-LD í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
    output = {
        **CONTEXT,
        "@graph": list(data.values())
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"  âœ… {class_name}: {len(data)}ê°œ â†’ {output_path.name}")


def main():
    """Phase B ë©”ì¸ ì‹¤í–‰"""
    print("=" * 60)
    print("Phase B: Reference í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
    print("=" * 60)

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # ì…ë ¥ íŒŒì¼ ëª©ë¡
    files = sorted(INPUT_DIR.glob("*.xlsx"))
    print(f"\nì…ë ¥ íŒŒì¼: {len(files)}ê°œ")

    # ëª¨ë“  Excel íŒŒì¼ ë¡œë“œ
    print("\n[1/9] ë°ì´í„° ë¡œë”© ì¤‘...")
    all_data = []
    for filepath in files:
        df = load_excel_file(filepath)
        if not df.empty:
            all_data.append(df)
    print(f"  ë¡œë“œ ì™„ë£Œ: {len(all_data)}ê°œ íŒŒì¼")

    # 1. Meeting
    print("\n[2/9] Meeting ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
    meetings = generate_meetings(files)
    save_jsonld(meetings, OUTPUT_DIR / "meetings.jsonld", "Meeting")

    # 2. Release
    print("\n[3/9] Release ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
    releases = generate_releases(all_data)
    save_jsonld(releases, OUTPUT_DIR / "releases.jsonld", "Release")

    # 3. Company
    print("\n[4/9] Company ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
    aliases_path = INTERMEDIATE_DIR / "company_aliases_significant.json"
    if aliases_path.exists():
        companies = generate_companies(aliases_path)
        save_jsonld(companies, OUTPUT_DIR / "companies.jsonld", "Company")
    else:
        print(f"  âš ï¸ {aliases_path} ì—†ìŒ - Phase Aë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”")
        companies = {}

    # 4. Contact
    print("\n[5/9] Contact ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
    contacts = generate_contacts(all_data)
    save_jsonld(contacts, OUTPUT_DIR / "contacts.jsonld", "Contact")

    # 5. WorkItem
    print("\n[6/9] WorkItem ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
    work_items = generate_work_items(all_data)
    save_jsonld(work_items, OUTPUT_DIR / "work_items.jsonld", "WorkItem")

    # 6. AgendaItem
    print("\n[7/9] AgendaItem ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
    agenda_items = generate_agenda_items(all_data)
    save_jsonld(agenda_items, OUTPUT_DIR / "agenda_items.jsonld", "AgendaItem")

    # 7. Spec
    print("\n[8/9] Spec ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
    specs = generate_specs(all_data)
    save_jsonld(specs, OUTPUT_DIR / "specs.jsonld", "Spec")

    # 8. WorkingGroup
    print("\n[9/9] WorkingGroup ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
    working_groups = generate_working_groups(all_data)
    save_jsonld(working_groups, OUTPUT_DIR / "working_groups.jsonld", "WorkingGroup")

    # ìš”ì•½
    print("\n" + "=" * 60)
    print("Phase B ì™„ë£Œ")
    print("=" * 60)
    print(f"\nğŸ“Š ìƒì„± ê²°ê³¼:")
    print(f"  Meeting:      {len(meetings):>6}ê°œ")
    print(f"  Release:      {len(releases):>6}ê°œ")
    print(f"  Company:      {len(companies):>6}ê°œ")
    print(f"  Contact:      {len(contacts):>6}ê°œ")
    print(f"  WorkItem:     {len(work_items):>6}ê°œ")
    print(f"  AgendaItem:   {len(agenda_items):>6}ê°œ")
    print(f"  Spec:         {len(specs):>6}ê°œ")
    print(f"  WorkingGroup: {len(working_groups):>6}ê°œ")
    print(f"  {'â”€' * 20}")
    total = sum([len(meetings), len(releases), len(companies), len(contacts),
                 len(work_items), len(agenda_items), len(specs), len(working_groups)])
    print(f"  ì´ê³„:         {total:>6}ê°œ")
    print(f"\nì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}")

    # Phase B ê²°ê³¼ë¥¼ intermediateì—ë„ ì €ì¥ (Phase Cì—ì„œ ì°¸ì¡°ìš©)
    reference_summary = {
        "meetings": list(meetings.keys()),
        "releases": list(releases.keys()),
        "companies": list(companies.keys()),
        "contacts": list(contacts.keys()),
        "work_items": list(work_items.keys()),
        "agenda_items": list(agenda_items.keys()),
        "specs": list(specs.keys()),
        "working_groups": list(working_groups.keys())
    }

    summary_path = INTERMEDIATE_DIR / "reference_summary.json"
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(reference_summary, f, ensure_ascii=False, indent=2)
    print(f"\nì°¸ì¡° ìš”ì•½ ì €ì¥: {summary_path}")


if __name__ == "__main__":
    main()
