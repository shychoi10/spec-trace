"""
BaseValidator: ëª¨ë“  Validatorì˜ ì¶”ìƒ ê¸°ë°˜ í´ë˜ìŠ¤

True Agentic AI ì›ì¹™ ì¤€ìˆ˜:
- ëª¨ë“  ê²€ì¦ ë¡œì§ì€ LLMì´ ìˆ˜í–‰
- Regex, í•˜ë“œì½”ë”©ëœ ê·œì¹™ ì‚¬ìš© ê¸ˆì§€
- 100% ì •í™•ë„ ëª©í‘œ, ìë™ ìˆ˜ì • ë£¨í”„ í¬í•¨

ê²€ì¦ í”Œë¡œìš°:
Validate â†’ [100% ë¯¸ë§Œ] â†’ Identify Errors â†’ Auto-Correct â†’ Re-validate
                â†“
         [ìµœëŒ€ 3íšŒ ë°˜ë³µ]
                â†“
         [ì—¬ì „íˆ ì‹¤íŒ¨] â†’ Manual Review Flag + ìƒì„¸ ì˜¤ë¥˜ ë¦¬í¬íŠ¸
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Optional
import json
import logging

logger = logging.getLogger(__name__)


class ValidationStatus(Enum):
    """ê²€ì¦ ìƒíƒœ"""
    PASS = "pass"           # 100% í†µê³¼
    FAIL = "fail"           # ê²€ì¦ ì‹¤íŒ¨ (ì˜¤ë¥˜ ë°œê²¬)
    CORRECTED = "corrected" # ìë™ ìˆ˜ì •ë¨
    MANUAL_REVIEW = "manual_review"  # ìˆ˜ë™ ê²€í†  í•„ìš”


@dataclass
class ValidationError:
    """ê°œë³„ ê²€ì¦ ì˜¤ë¥˜"""
    error_type: str
    description: str
    location: Optional[str] = None
    suggested_fix: Optional[str] = None
    severity: str = "error"  # error, warning, info


@dataclass
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼"""
    status: ValidationStatus
    accuracy: float  # 0.0 - 1.0
    errors: list[ValidationError] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)
    corrected_output: Optional[Any] = None
    validation_time_ms: float = 0.0
    retry_count: int = 0
    validator_name: str = ""
    notes: list[str] = field(default_factory=list)

    @property
    def is_perfect(self) -> bool:
        """100% ì •í™•ë„ì¸ì§€ í™•ì¸"""
        return self.accuracy >= 1.0 and len(self.errors) == 0

    def to_dict(self) -> dict:
        """JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ dict ë³€í™˜"""
        return {
            "status": self.status.value,
            "accuracy": self.accuracy,
            "errors": [
                {
                    "error_type": e.error_type,
                    "description": e.description,
                    "location": e.location,
                    "suggested_fix": e.suggested_fix,
                    "severity": e.severity,
                }
                for e in self.errors
            ],
            "warnings": self.warnings,
            "validation_time_ms": self.validation_time_ms,
            "retry_count": self.retry_count,
            "validator_name": self.validator_name,
            "notes": self.notes,
        }


class BaseValidator(ABC):
    """
    ëª¨ë“  Validatorì˜ ê¸°ë°˜ ì¶”ìƒ í´ë˜ìŠ¤

    100% ì •í™•ë„ ëª©í‘œì˜ ê²€ì¦ ë£¨í”„:
    1. validate(): ì´ˆê¸° ê²€ì¦
    2. identify_errors(): ì˜¤ë¥˜ ì‹ë³„ (LLM)
    3. auto_correct(): ìë™ ìˆ˜ì • ì‹œë„ (LLM)
    4. re-validate: ìˆ˜ì • í›„ ì¬ê²€ì¦
    5. ìµœëŒ€ 3íšŒ ë°˜ë³µ, ì‹¤íŒ¨ ì‹œ manual_review í”Œë˜ê·¸
    """

    # ì„¤ì •
    MAX_CORRECTION_ATTEMPTS = 3
    TARGET_ACCURACY = 1.0  # 100%

    def __init__(self, llm_manager, config: Optional[dict] = None):
        """
        Args:
            llm_manager: LLM í˜¸ì¶œ ë§¤ë‹ˆì €
            config: ê²€ì¦ê¸° ì„¤ì •
        """
        self.llm = llm_manager
        self.validator_name = self.__class__.__name__
        self.config = config or {}
        self.validation_history: list[ValidationResult] = []

    @abstractmethod
    def validate(self, data: Any, context: Optional[dict] = None) -> ValidationResult:
        """
        í•µì‹¬ ê²€ì¦ ë¡œì§ (LLM ì‚¬ìš©)

        Args:
            data: ê²€ì¦í•  ë°ì´í„°
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì›ë³¸ ë¬¸ì„œ ë“±)

        Returns:
            ValidationResult
        """
        pass

    @abstractmethod
    def identify_errors(
        self, data: Any, validation_result: ValidationResult
    ) -> list[ValidationError]:
        """
        ì˜¤ë¥˜ ìƒì„¸ ì‹ë³„ (LLM ì‚¬ìš©)

        Args:
            data: ê²€ì¦ ëŒ€ìƒ ë°ì´í„°
            validation_result: ì´ˆê¸° ê²€ì¦ ê²°ê³¼

        Returns:
            ì‹ë³„ëœ ì˜¤ë¥˜ ëª©ë¡
        """
        pass

    @abstractmethod
    def auto_correct(
        self, data: Any, errors: list[ValidationError]
    ) -> tuple[Any, bool]:
        """
        ìë™ ìˆ˜ì • ì‹œë„ (LLM ì‚¬ìš©)

        Args:
            data: ì›ë³¸ ë°ì´í„°
            errors: ìˆ˜ì •í•  ì˜¤ë¥˜ ëª©ë¡

        Returns:
            (ìˆ˜ì •ëœ ë°ì´í„°, ìˆ˜ì • ì„±ê³µ ì—¬ë¶€)
        """
        pass

    def validate_with_correction_loop(
        self, data: Any, context: Optional[dict] = None
    ) -> ValidationResult:
        """
        100% ì •í™•ë„ ë‹¬ì„±ì„ ìœ„í•œ ìë™ ìˆ˜ì • ë£¨í”„

        í”Œë¡œìš°:
        1. ì´ˆê¸° ê²€ì¦
        2. 100% ë¯¸ë‹¬ ì‹œ ì˜¤ë¥˜ ì‹ë³„
        3. ìë™ ìˆ˜ì • ì‹œë„
        4. ì¬ê²€ì¦
        5. ìµœëŒ€ 3íšŒ ë°˜ë³µ
        6. ì‹¤íŒ¨ ì‹œ manual_review í”Œë˜ê·¸

        Args:
            data: ê²€ì¦í•  ë°ì´í„°
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸

        Returns:
            ìµœì¢… ValidationResult
        """
        start_time = datetime.now()
        current_data = data
        attempt = 0

        while attempt < self.MAX_CORRECTION_ATTEMPTS:
            # 1. ê²€ì¦ ì‹¤í–‰
            result = self.validate(current_data, context)
            result.retry_count = attempt
            result.validator_name = self.validator_name

            logger.info(
                f"[{self.validator_name}] Attempt {attempt + 1}: "
                f"Accuracy={result.accuracy:.2%}, Errors={len(result.errors)}"
            )

            # 2. 100% ë‹¬ì„± ì‹œ ì„±ê³µ
            if result.is_perfect:
                result.status = ValidationStatus.PASS
                result.validation_time_ms = (
                    datetime.now() - start_time
                ).total_seconds() * 1000
                self.validation_history.append(result)
                logger.info(f"[{self.validator_name}] âœ… Validation passed (100%)")
                return result

            # 3. ì˜¤ë¥˜ ì‹ë³„
            errors = self.identify_errors(current_data, result)
            if not errors:
                # ì˜¤ë¥˜ë¥¼ ì‹ë³„í•  ìˆ˜ ì—†ìœ¼ë©´ í˜„ì¬ ê²°ê³¼ ë°˜í™˜
                logger.warning(
                    f"[{self.validator_name}] Could not identify errors, "
                    f"returning current result"
                )
                break

            # 4. ìë™ ìˆ˜ì • ì‹œë„
            corrected_data, correction_success = self.auto_correct(current_data, errors)

            if not correction_success:
                logger.warning(
                    f"[{self.validator_name}] Auto-correction failed at attempt {attempt + 1}"
                )
                break

            # 5. ë‹¤ìŒ iterationì„ ìœ„í•´ ë°ì´í„° ì—…ë°ì´íŠ¸
            current_data = corrected_data
            attempt += 1

            logger.info(
                f"[{self.validator_name}] Applied corrections, retrying validation..."
            )

        # ìµœëŒ€ ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨ â†’ Manual Review í•„ìš”
        final_result = self.validate(current_data, context)
        final_result.status = ValidationStatus.MANUAL_REVIEW
        final_result.retry_count = attempt
        final_result.validator_name = self.validator_name
        final_result.validation_time_ms = (
            datetime.now() - start_time
        ).total_seconds() * 1000
        final_result.notes.append(
            f"Manual review required after {attempt} correction attempts"
        )

        if current_data != data:
            final_result.corrected_output = current_data
            final_result.status = ValidationStatus.CORRECTED

        self.validation_history.append(final_result)
        logger.warning(
            f"[{self.validator_name}] âš ï¸ Validation incomplete. "
            f"Accuracy={final_result.accuracy:.2%}, Status={final_result.status.value}"
        )

        return final_result

    # =========================================================================
    # LLM Helper Methods
    # =========================================================================

    def _call_llm_for_validation(
        self, prompt: str, temperature: float = 0.1
    ) -> dict:
        """
        ê²€ì¦ìš© LLM í˜¸ì¶œ (JSON ì‘ë‹µ ê¸°ëŒ€)

        Args:
            prompt: ê²€ì¦ í”„ë¡¬í”„íŠ¸
            temperature: LLM temperature (ê²€ì¦ì€ ë‚®ì€ ê°’ ê¶Œì¥)

        Returns:
            íŒŒì‹±ëœ JSON dict
        """
        try:
            response = self.llm.generate(prompt, temperature=temperature, max_tokens=2000)
            return self._parse_json_response(response)
        except Exception as e:
            logger.error(f"[{self.validator_name}] LLM call failed: {e}")
            return {}

    def _parse_json_response(self, response: str) -> dict:
        """
        LLM ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ

        Args:
            response: LLM ì‘ë‹µ ë¬¸ìì—´

        Returns:
            íŒŒì‹±ëœ dict (ì‹¤íŒ¨ ì‹œ ë¹ˆ dict)
        """
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ
            if "```json" in response:
                json_str = response.split("```json")[1].split("```")[0].strip()
            elif "```" in response:
                json_str = response.split("```")[1].split("```")[0].strip()
            else:
                # ì „ì²´ê°€ JSONì¼ ìˆ˜ ìˆìŒ
                json_str = response.strip()

            return json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.warning(f"[{self.validator_name}] JSON parse error: {e}")
            return {}
        except Exception as e:
            logger.warning(f"[{self.validator_name}] Unexpected parse error: {e}")
            return {}

    # =========================================================================
    # Reporting Methods
    # =========================================================================

    def generate_report(self, result: ValidationResult) -> str:
        """
        ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„± (Markdown)

        Args:
            result: ê²€ì¦ ê²°ê³¼

        Returns:
            Markdown í˜•ì‹ ë¦¬í¬íŠ¸
        """
        status_emoji = {
            ValidationStatus.PASS: "âœ…",
            ValidationStatus.FAIL: "âŒ",
            ValidationStatus.CORRECTED: "ğŸ”§",
            ValidationStatus.MANUAL_REVIEW: "âš ï¸",
        }

        lines = [
            f"## {self.validator_name} Validation Report",
            "",
            f"**Status**: {status_emoji.get(result.status, '?')} {result.status.value.upper()}",
            f"**Accuracy**: {result.accuracy:.1%}",
            f"**Retry Count**: {result.retry_count}",
            f"**Time**: {result.validation_time_ms:.1f}ms",
            "",
        ]

        if result.errors:
            lines.append("### Errors Found")
            for i, error in enumerate(result.errors, 1):
                lines.append(f"{i}. **{error.error_type}**: {error.description}")
                if error.location:
                    lines.append(f"   - Location: {error.location}")
                if error.suggested_fix:
                    lines.append(f"   - Suggested fix: {error.suggested_fix}")
            lines.append("")

        if result.warnings:
            lines.append("### Warnings")
            for warning in result.warnings:
                lines.append(f"- {warning}")
            lines.append("")

        if result.notes:
            lines.append("### Notes")
            for note in result.notes:
                lines.append(f"- {note}")
            lines.append("")

        return "\n".join(lines)
