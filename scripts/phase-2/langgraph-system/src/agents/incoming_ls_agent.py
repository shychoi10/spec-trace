"""
Incoming LS Agent: True Agentic AI Orchestrator

ì´ì œ 266ì¤„ í”„ë¡¬í”„íŠ¸ ëŒ€ì‹ , 5ê°œì˜ Sub-Agentë¥¼ ì¡°ìœ¨í•©ë‹ˆë‹¤:
1. IssueSplitter â†’ Issue ê²½ê³„ ì‹ë³„
2. TdocsExtractor â†’ ëª¨ë“  Tdocs ì¶”ì¶œ (Gemini ê°•ì )
3. TdocsSelector â†’ 1-3ê°œ ì„ íƒ (Dynamic Prompting)
4. IssueFormatter â†’ Markdown ìƒì„±
5. SectionOverview â†’ ì „ì²´ ìš”ì•½

True Agentic AI: ì •ê·œì‹ ì‚¬ìš© ê¸ˆì§€, ëª¨ë“  ë¶„ì„ì€ LLMì´ ìˆ˜í–‰
"""

from typing import Dict, Any, List
from .base_agent import BaseAgent
from .sub_agents import (
    IssueSplitterAgent,
    TdocsExtractorAgent,
    TdocsSelectorAgent,
    IssueFormatterAgent,
    SectionOverviewAgent,
)


class IncomingLSAgent(BaseAgent):
    """Incoming LS ì²˜ë¦¬ Orchestrator Agent (True Agentic AI)"""

    # Incoming LS ê°ì§€ìš© í‚¤ì›Œë“œ (LLM í”„ë¡¬í”„íŠ¸ì—ì„œ ì‚¬ìš©)
    KEYWORDS = [
        "LS on",
        "Reply LS",
        "incoming LS",
        "liaison statement",
        "LS to",
        "LS from",
    ]

    def __init__(self, llm_manager):
        super().__init__(llm_manager)

        # Sub-Agent ì´ˆê¸°í™”
        print(f"[{self.agent_name}] Initializing Sub-Agents...")
        self.splitter = IssueSplitterAgent(llm_manager)
        self.extractor = TdocsExtractorAgent(llm_manager)
        self.selector = TdocsSelectorAgent(llm_manager)
        self.formatter = IssueFormatterAgent(llm_manager)
        self.overview_gen = SectionOverviewAgent(llm_manager)
        print(f"[{self.agent_name}] âœ… 5 Sub-Agents initialized")

    def detect_pattern(self, content: str) -> float:
        """
        Incoming LS íŒ¨í„´ ê°ì§€ ì ìˆ˜ ê³„ì‚° (True Agentic AI - í‚¤ì›Œë“œ ê¸°ë°˜)

        LLM í˜¸ì¶œ ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•´ ë‹¨ìˆœ í‚¤ì›Œë“œ ì¡´ìž¬ ì—¬ë¶€ë§Œ í™•ì¸í•©ë‹ˆë‹¤.
        ì‹¤ì œ ë¶„ë¥˜ì™€ ë¶„ì„ì€ LLMì´ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            content: ë¶„ì„í•  í…ìŠ¤íŠ¸

        Returns:
            0.0-1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„ ì ìˆ˜
        """
        content_lower = content.lower()
        matches = 0

        # ë‹¨ìˆœ í‚¤ì›Œë“œ ì¡´ìž¬ í™•ì¸ (ë¶„ë¥˜ê°€ ì•„ë‹Œ í•„í„°ë§ ëª©ì )
        for keyword in self.KEYWORDS:
            if keyword.lower() in content_lower:
                matches += 1

        # í‚¤ì›Œë“œê°€ ë§Žì´ ë°œê²¬ë ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        if matches > 0:
            return min(1.0, 0.3 + (matches * 0.2))
        return 0.0

    def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Incoming LS ì²˜ë¦¬ (True Agentic AI, ì½˜í…ì¸  ê¸°ë°˜)

        Args:
            state: LangGraph state
                - content: Incoming LS í…ìŠ¤íŠ¸ (ì½˜í…ì¸  ê¸°ë°˜)
                - metadata: {meeting_number, ...}

        Returns:
            ì—…ë°ì´íŠ¸ëœ state
                - structured_output: ì™„ì „í•œ Markdown
                - agent_used: "IncomingLSAgent"
        """
        content = state.get("content", "")
        metadata = state.get("metadata", {})
        meeting_number = metadata.get("meeting_number", "Unknown")

        print(f"\n{'='*80}")
        print(f"[{self.agent_name}] Processing Incoming LS (True Agentic AI)")
        print(f"{'='*80}")

        # ========== Stage 1: Issue Splitting ==========
        print(f"\nðŸ”¹ Stage 1: Issue Splitting (LLM Autonomy)")
        all_issues = self.splitter.process(content, metadata)

        if not all_issues:
            print(f"[{self.agent_name}] âŒ No issues identified. Aborting.")
            state["structured_output"] = "# Error: No LS items identified"
            state["agent_used"] = self.agent_name
            return state

        # Primary vs CC-only ë¶„ë¦¬
        primary_issues = [i for i in all_issues if i.get("is_primary", True)]
        cc_only_issues = [i for i in all_issues if not i.get("is_primary", True)]

        print(
            f"[{self.agent_name}] Identified: {len(primary_issues)} Primary + {len(cc_only_issues)} CC-only"
        )

        # ========== Stage 2-4: Process Each Primary Issue ==========
        print(f"\nðŸ”¹ Stage 2-4: Processing {len(primary_issues)} Primary Issues")
        processed_issues: List[str] = []

        for idx, issue in enumerate(primary_issues, start=1):
            ls_id = issue["ls_id"]
            print(
                f"\n--- Processing Issue {idx}/{len(primary_issues)}: {ls_id} ---"
            )

            # Stage 2: Extract ALL Tdocs (Gemini ê°•ì  í™œìš©)
            all_tdocs_markdown = self.extractor.process(issue)

            # Stage 3: Select 1-3 Tdocs (Dynamic Prompting)
            selected_tdocs_markdown = self.selector.process(
                issue, all_tdocs_markdown
            )

            # Stage 4: Format Issue (Markdown)
            issue_markdown = self.formatter.process(
                issue, selected_tdocs_markdown, idx
            )

            processed_issues.append(issue_markdown)

        # ========== Stage 5: Self-Validation (Moderate) ==========
        print(f"\nðŸ”¹ Stage 5: Self-Validation (Moderate)")
        validation_result = self._validate_issues(processed_issues)

        if not validation_result["valid"]:
            print(
                f"[{self.agent_name}] âš ï¸  Validation warnings: {validation_result['errors']}"
            )
        else:
            print(f"[{self.agent_name}] âœ… Issues validated successfully")

        # ========== Stage 6: Section Overview ==========
        print(f"\nðŸ”¹ Stage 6: Section Overview Generation")
        section_overview = self.overview_gen.process(all_issues, meeting_number)

        # ========== Stage 7: CC-only Items (if any) ==========
        cc_only_markdown = ""
        if cc_only_issues:
            print(
                f"\nðŸ”¹ Stage 7: Formatting {len(cc_only_issues)} CC-only Items"
            )
            cc_only_markdown = self._format_cc_only_issues(cc_only_issues)

        # ========== Final Assembly ==========
        print(f"\nðŸ”¹ Final: Assembling Complete Markdown")
        final_output = (
            section_overview
            + "\n\n"
            + "\n\n".join(processed_issues)
            + "\n\n"
            + cc_only_markdown
        )

        # State ì—…ë°ì´íŠ¸
        state["structured_output"] = final_output
        state["agent_used"] = self.agent_name

        print(f"\n{'='*80}")
        print(
            f"[{self.agent_name}] âœ… Processing Complete ({len(final_output)} chars)"
        )
        print(f"{'='*80}")

        return state

    def _validate_issues(self, issues: List[str]) -> Dict[str, Any]:
        """
        Moderate self-validation for processed Issues

        Args:
            issues: List of Issue Markdown strings

        Returns:
            {"valid": bool, "errors": [...], "warnings": [...]}
        """
        print(
            f"[{self.agent_name}] Validating {len(issues)} processed Issues..."
        )

        # ìƒ˜í”Œë¡œ ì²« 3ê°œë§Œ LLMì—ê²Œ ë³´ì—¬ì¤Œ (ë¹„ìš© ì ˆê°)
        sample_issues = "\n\n".join(issues[:3]) + "\n\n... (more issues)"

        validation_prompt = f"""Validate these processed Issues for completeness.

Total Issues: {len(issues)}

Sample (first 3):
{sample_issues}

Check:
1. Do all Issues have required fields?
   - Origin (Type, LS ID, Source WG)
   - Summary (Korean)
   - Relevant Tdocs
   - Decision
   - Agenda Item
   - Issue Type

2. Are Issue numbers sequential (Issue 1, Issue 2, Issue 3...)?

3. Are Tdocs properly categorized with tags (`discussion`, `ls_reply_draft`)?

4. For Non-action Issues, are Tdocs "ì—†ìŒ"?

Output (JSON):
{{
  "valid": true or false,
  "errors": ["error 1", "error 2"],
  "warnings": ["warning 1"]
}}

Generate validation result:
"""

        try:
            import json

            response = self.llm.generate(
                validation_prompt, temperature=0.0, max_tokens=1000
            )
            validation = json.loads(response)
            return validation
        except Exception as e:
            print(f"[{self.agent_name}] Validation LLM call failed: {e}")
            return {
                "valid": True,
                "errors": [],
                "warnings": ["Validation skipped due to error"],
            }

    def _format_cc_only_issues(
        self, cc_only_issues: List[Dict[str, Any]]
    ) -> str:
        """
        Format CC-only items section

        Args:
            cc_only_issues: List of CC-only issue dicts

        Returns:
            CC-only section Markdown
        """
        cc_markdown = "### RAN1 was cc-ed in the following incoming LSs\n\n"

        for issue in cc_only_issues:
            ls_id = issue["ls_id"]
            title = issue["title"]
            cc_markdown += f"#### {ls_id}: {title}\n\n"
            cc_markdown += f"**Decision:** {issue['decision_text']}\n\n"

        return cc_markdown
